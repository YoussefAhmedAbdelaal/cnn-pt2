{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad04131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ReLU:\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        self.output = np.maximum(0, x)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        return grad_output * (self.input > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59c0b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvolutionalLayer:\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.filters = np.random.randn(out_channels, in_channels, kernel_size, kernel_size) * 0.01\n",
    "        self.biases = np.zeros((out_channels, 1, 1))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input = input_data\n",
    "        n_samples, n_channels, height, width = input_data.shape\n",
    "        filter_height, filter_width = self.filters.shape[2], self.filters.shape[3]\n",
    "        out_height = (height - filter_height + 2 * self.padding) // self.stride + 1\n",
    "        out_width = (width - filter_width + 2 * self.padding) // self.stride + 1\n",
    "        output = np.zeros((n_samples, self.out_channels, out_height, out_width))\n",
    "        padded_input = np.pad(input_data, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
    "        for i in range(n_samples):\n",
    "            for f in range(self.out_channels):\n",
    "                for y in range(0, out_height, self.stride):\n",
    "                    for x in range(0, out_width, self.stride):\n",
    "                        input_slice = padded_input[i, :, y:y + filter_height, x:x + filter_width]\n",
    "                        output[i, f, y // self.stride, x // self.stride] = np.sum(input_slice * self.filters[f]) + self.biases[f]\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.zeros_like(self.input)\n",
    "        grad_filters = np.zeros_like(self.filters)\n",
    "        grad_biases = np.zeros_like(self.biases)\n",
    "        n_samples, n_channels, height, width = self.input.shape\n",
    "        filter_height, filter_width = self.filters.shape[2], self.filters.shape[3]\n",
    "        out_height, out_width = grad_output.shape[2], grad_output.shape[3]\n",
    "        padded_input = np.pad(self.input, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
    "        padded_grad_input = np.pad(grad_input, ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding)), mode='constant')\n",
    "        for i in range(n_samples):\n",
    "            for f in range(self.out_channels):\n",
    "                for y in range(out_height):\n",
    "                    for x in range(out_width):\n",
    "                        dy = y * self.stride\n",
    "                        dx = x * self.stride\n",
    "                        input_slice = padded_input[i, :, dy:dy + filter_height, dx:dx + filter_width]\n",
    "                        grad = grad_output[i, f, y, x]\n",
    "                        padded_grad_input[i, :, dy:dy + filter_height, dx:dx + filter_width] += grad * self.filters[f]\n",
    "                        grad_filters[f] += grad * input_slice\n",
    "                        grad_biases[f] += grad\n",
    "        self.filters -= learning_rate * grad_filters\n",
    "        self.biases -= learning_rate * grad_biases\n",
    "        return padded_grad_input[:, :, self.padding:-self.padding, self.padding:-self.padding]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e96c83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Part 3: MaxPooling and Flatten Layers ---\n",
    "class MaxPoolingLayer:\n",
    "    def __init__(self, pool_size, stride=None):\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride if stride is not None else pool_size\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input = input_data\n",
    "        n_samples, n_channels, height, width = input_data.shape\n",
    "        out_height = (height - self.pool_size) // self.stride + 1\n",
    "        out_width = (width - self.pool_size) // self.stride + 1\n",
    "        output = np.zeros((n_samples, n_channels, out_height, out_width))\n",
    "        self.max_indices = np.zeros_like(input_data, dtype=bool)\n",
    "        for i in range(n_samples):\n",
    "            for c in range(n_channels):\n",
    "                for y in range(0, height - self.pool_size + 1, self.stride):\n",
    "                    for x in range(0, width - self.pool_size + 1, self.stride):\n",
    "                        pool_region = input_data[i, c, y:y + self.pool_size, x:x + self.pool_size]\n",
    "                        max_val = np.max(pool_region)\n",
    "                        output[i, c, y // self.stride, x // self.stride] = max_val\n",
    "                        (max_y, max_x) = np.unravel_index(pool_region.argmax(), pool_region.shape)\n",
    "                        self.max_indices[i, c, y + max_y, x + max_x] = 1\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.zeros_like(self.input)\n",
    "        n_samples, n_channels, out_height, out_width = grad_output.shape\n",
    "        for i in range(n_samples):\n",
    "            for c in range(n_channels):\n",
    "                for y in range(out_height):\n",
    "                    for x in range(out_width):\n",
    "                        dy = y * self.stride\n",
    "                        dx = x * self.stride\n",
    "                        grad_input[i, c, dy:dy + self.pool_size, dx:dx + self.pool_size] += (\n",
    "                            grad_output[i, c, y, x] * self.max_indices[i, c, dy:dy + self.pool_size, dx:dx + self.pool_size]\n",
    "                        )\n",
    "        return grad_input\n",
    "\n",
    "class FlattenLayer:\n",
    "    def forward(self, input_data):\n",
    "        self.input_shape = input_data.shape\n",
    "        return input_data.reshape(input_data.shape[0], -1)\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        return grad_output.reshape(self.input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d863272c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(input_size, output_size) * 0.01\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input = input_data\n",
    "        return np.dot(input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad_input = np.dot(grad_output, self.weights.T)\n",
    "        grad_weights = np.dot(self.input.T, grad_output)\n",
    "        grad_biases = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        self.biases -= learning_rate * grad_biases\n",
    "        return grad_input\n",
    "\n",
    "class Softmax:\n",
    "    def forward(self, x):\n",
    "        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        self.output = exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        return grad_output\n",
    "\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    m = y_true.shape[0]\n",
    "    log_likelihood = -np.log(y_pred[np.arange(m), y_true])\n",
    "    loss = np.sum(log_likelihood) / m\n",
    "    return loss\n",
    "\n",
    "def cross_entropy_backward(y_pred, y_true):\n",
    "    m = y_true.shape[0]\n",
    "    grad = y_pred.copy()\n",
    "    grad[np.arange(m), y_true] -= 1\n",
    "    grad = grad / m\n",
    "    return grad\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0665bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO_YOGA7\\AppData\\Local\\Temp\\ipykernel_17472\\4030753718.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  output[i, f, y // self.stride, x // self.stride] = np.sum(input_slice * self.filters[f]) + self.biases[f]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Sample 1/10, Loss: 0.6931\n",
      "Epoch 1/5, Sample 2/10, Loss: 0.6982\n",
      "Epoch 1/5, Sample 3/10, Loss: 0.6932\n",
      "Epoch 1/5, Sample 4/10, Loss: 0.6981\n",
      "Epoch 1/5, Sample 5/10, Loss: 0.6932\n",
      "Epoch 1/5, Sample 6/10, Loss: 0.6981\n",
      "Epoch 1/5, Sample 7/10, Loss: 0.6932\n",
      "Epoch 1/5, Sample 8/10, Loss: 0.6981\n",
      "Epoch 1/5, Sample 9/10, Loss: 0.6931\n",
      "Epoch 1/5, Sample 10/10, Loss: 0.6881\n",
      "Epoch 2/5, Sample 1/10, Loss: 0.6831\n",
      "Epoch 2/5, Sample 2/10, Loss: 0.7083\n",
      "Epoch 2/5, Sample 3/10, Loss: 0.7031\n",
      "Epoch 2/5, Sample 4/10, Loss: 0.6883\n",
      "Epoch 2/5, Sample 5/10, Loss: 0.7031\n",
      "Epoch 2/5, Sample 6/10, Loss: 0.6884\n",
      "Epoch 2/5, Sample 7/10, Loss: 0.7030\n",
      "Epoch 2/5, Sample 8/10, Loss: 0.6884\n",
      "Epoch 2/5, Sample 9/10, Loss: 0.6835\n",
      "Epoch 2/5, Sample 10/10, Loss: 0.6786\n",
      "Epoch 3/5, Sample 1/10, Loss: 0.6737\n",
      "Epoch 3/5, Sample 2/10, Loss: 0.7179\n",
      "Epoch 3/5, Sample 3/10, Loss: 0.7127\n",
      "Epoch 3/5, Sample 4/10, Loss: 0.6790\n",
      "Epoch 3/5, Sample 5/10, Loss: 0.7125\n",
      "Epoch 3/5, Sample 6/10, Loss: 0.6791\n",
      "Epoch 3/5, Sample 7/10, Loss: 0.7124\n",
      "Epoch 3/5, Sample 8/10, Loss: 0.6793\n",
      "Epoch 3/5, Sample 9/10, Loss: 0.6744\n",
      "Epoch 3/5, Sample 10/10, Loss: 0.6696\n",
      "Epoch 4/5, Sample 1/10, Loss: 0.6649\n",
      "Epoch 4/5, Sample 2/10, Loss: 0.7272\n",
      "Epoch 4/5, Sample 3/10, Loss: 0.7219\n",
      "Epoch 4/5, Sample 4/10, Loss: 0.6702\n",
      "Epoch 4/5, Sample 5/10, Loss: 0.7216\n",
      "Epoch 4/5, Sample 6/10, Loss: 0.6705\n",
      "Epoch 4/5, Sample 7/10, Loss: 0.7214\n",
      "Epoch 4/5, Sample 8/10, Loss: 0.6707\n",
      "Epoch 4/5, Sample 9/10, Loss: 0.6659\n",
      "Epoch 4/5, Sample 10/10, Loss: 0.6612\n",
      "Epoch 5/5, Sample 1/10, Loss: 0.6565\n",
      "Epoch 5/5, Sample 2/10, Loss: 0.7361\n",
      "Epoch 5/5, Sample 3/10, Loss: 0.7307\n",
      "Epoch 5/5, Sample 4/10, Loss: 0.6619\n",
      "Epoch 5/5, Sample 5/10, Loss: 0.7304\n",
      "Epoch 5/5, Sample 6/10, Loss: 0.6623\n",
      "Epoch 5/5, Sample 7/10, Loss: 0.7300\n",
      "Epoch 5/5, Sample 8/10, Loss: 0.6626\n",
      "Epoch 5/5, Sample 9/10, Loss: 0.6579\n",
      "Epoch 5/5, Sample 10/10, Loss: 0.6533\n",
      "Predictions: [1 1]\n"
     ]
    }
   ],
   "source": [
    "class CNN:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        output = input_data\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        grad = grad_output\n",
    "        for layer in reversed(self.layers):\n",
    "            grad = layer.backward(grad, learning_rate)\n",
    "        return grad\n",
    "\n",
    "    def train(self, X_train, y_train, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(X_train.shape[0]):\n",
    "                input_sample = X_train[i][np.newaxis, ...]\n",
    "                target = y_train[i]\n",
    "                output = self.forward(input_sample)\n",
    "                probs = self.layers[-1].output\n",
    "                loss = cross_entropy_loss(probs, np.array([target]))\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Sample {i+1}/{X_train.shape[0]}, Loss: {loss:.4f}\")\n",
    "                grad = cross_entropy_backward(probs, np.array([target]))\n",
    "                self.backward(grad, learning_rate)\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train_ex = np.random.rand(10, 1, 8, 8)\n",
    "    y_train_ex = np.random.randint(0, 2, 10)\n",
    "\n",
    "    cnn = CNN()\n",
    "    cnn.add(ConvolutionalLayer(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1))\n",
    "    cnn.add(ReLU())\n",
    "    cnn.add(MaxPoolingLayer(pool_size=2, stride=2))\n",
    "    cnn.add(FlattenLayer())\n",
    "    cnn.add(DenseLayer(input_size=4 * 4 * 4, output_size=10))\n",
    "    cnn.add(ReLU())\n",
    "    cnn.add(DenseLayer(input_size=10, output_size=2))\n",
    "    cnn.add(Softmax())\n",
    "\n",
    "    cnn.train(X_train_ex, y_train_ex, epochs=5, learning_rate=0.01)\n",
    "\n",
    "    X_test_ex = np.random.rand(2, 1, 8, 8)\n",
    "    predictions = cnn.predict(X_test_ex)\n",
    "    print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff5e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
